---
title: "L7"
author: "Kovel"
date: '31 РѕРєС‚СЏР±СЂСЏ 2020 Рі '
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Download the data
```{r}
set.seed(123)
f_train <- read.csv2('education_train.csv', header = TRUE, encoding = 'UNICOD')
f_test <- read.csv2('education_test.csv', header = TRUE, encoding = 'UNICOD')
f_train <- f_train[-1]
f_test <- f_test[-1]
```
##Висновок: завантажано датасет,який було розподілено на навчальну та тестову вибірки.
# Fitting & predicting
```{r}
library(class)
y = knn(train = f_train[,c('age','traveltime')],
        test = f_test[,c('age','traveltime')],
        cl = f_train[, 'school'],
        k = 16,
        prob = TRUE)
```
##Висновок:  і навчання, і прогнозування за моделлю k найближчих сусідів здійснюється однією функцією. У результаті отримуємо вектор класів об’єктів.
## Confusion Matrix
```{r}
cm = table(f_test[, 'school'], y == '1')
print(cm)
```
##Висновок: точність моделі – (115+1) / 131 = 88,5 %, частка невірно класифікованих випадків – (15+0) / 131 = 11,4 %. Чутливість – 1 / (15+1) = 6 %, специфічність – 115 / (115+0) = 100 %, тобто модель більш чутлива до виявлення негативних випадків. 
## Visualising the Test set results
```{r}
library(ggplot2)
set = f_test[,c('age','traveltime','school')]
X1 = seq(min(set['age']) - 1, max(set['age']) + 1, by = 0.01)
X2 = seq(min(set['traveltime']) - 1, max(set['traveltime']) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('age', 'traveltime')
y_grid = knn(train = f_train[,c('age','traveltime')], test = grid_set, cl = f_train[, 'school'], k = 5)
plot(set[, -3],
     main = 'KNN',
     xlab = 'Age', ylab = 'Traveltime',
     xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'tomato', 'springgreen3'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'red3', 'green4'))
```
##Висновок: на графіку червоним позначені випадки потрапляння до школи першого типу, зеленим – ло другого. Червоним виділена зона високої ймовірності потрапляння до першого типу. Модель описує нелінійний варіант розподіляючої кривої.